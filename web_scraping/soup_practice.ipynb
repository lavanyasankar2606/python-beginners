{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: How to scrape multiple things from multiple pages\n",
    "\n",
    "The goal is to scrape info about the five top-grossing movies for each year, for 10 years. I want the title and rank of the movie, and also, how much money did it gross at the box office. In the end I will put the scraped data into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.boxofficemojo.com/yearly/chart/?yr=2018'\n",
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# I discover the data I want is in an HTML table with no class or ID \n",
    "tables = soup.find_all( 'table' )\n",
    "print(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Panther\n"
     ]
    }
   ],
   "source": [
    "# I had to test a few numbers before I got the correct tables[] and rows[] numbers\n",
    "# I just kept changing the number and printing until I found it\n",
    "rows = tables[6].find_all('tr')\n",
    "# print(len(rows))\n",
    "# print(rows[2])\n",
    "cells = rows[2].find_all('td')\n",
    "title = cells[1].text\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Panther\n",
      "Avengers: Infinity War\n",
      "Incredibles 2\n",
      "Jurassic World: Fallen Kingdom\n",
      "Aquaman\n"
     ]
    }
   ],
   "source": [
    "# get top 5 movies on this page - I know the first row is [2]\n",
    "for i in range(2, 7):\n",
    "    cells = rows[i].find_all('td')\n",
    "    title = cells[1].text\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$700,059,566\n",
      "$678,815,482\n",
      "$608,581,744\n",
      "$417,719,760\n",
      "$335,038,565\n"
     ]
    }
   ],
   "source": [
    "# I would like to get the total gross number also\n",
    "for i in range(2, 7):\n",
    "    cells = rows[i].find_all('td')\n",
    "    gross = cells[3].text\n",
    "    print(gross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Black Panther $700,059,566\n",
      "2 Avengers: Infinity War $678,815,482\n",
      "3 Incredibles 2 $608,581,744\n",
      "4 Jurassic World: Fallen Kingdom $417,719,760\n",
      "5 Aquaman $335,038,565\n"
     ]
    }
   ],
   "source": [
    "# next I want to get rank (1-5), title and gross all on one line\n",
    "for i in range(2, 7):\n",
    "    cells = rows[i].find_all('td')\n",
    "    print(cells[0].text, cells[1].text, cells[3].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011, 2010, 2009]\n"
     ]
    }
   ],
   "source": [
    "# I want to do this for 10 years, ending with 2018\n",
    "# first create a list of the years I want\n",
    "years = []\n",
    "start = 2018\n",
    "for i in range(0, 10):\n",
    "    years.append(start - i)\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.boxofficemojo.com/yearly/chart/?yr=2018\n"
     ]
    }
   ],
   "source": [
    "# create a base url so I can open each year's page\n",
    "base_url = 'https://www.boxofficemojo.com/yearly/chart/?yr='\n",
    "# test it\n",
    "# print(base_url + years[0]) -- ERROR\n",
    "print( base_url + str(years[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Black Panther $700,059,566\n",
      "2 Avengers: Infinity War $678,815,482\n",
      "3 Incredibles 2 $608,581,744\n",
      "4 Jurassic World: Fallen Kingdom $417,719,760\n",
      "5 Aquaman $335,038,565\n",
      "1 Star Wars: The Last Jedi $620,181,382\n",
      "2 Beauty and the Beast (2017) $504,014,165\n",
      "3 Wonder Woman $412,563,408\n",
      "4 Jumanji: Welcome to the Jungle $404,515,480\n",
      "5 Guardians of the Galaxy Vol. 2 $389,813,101\n",
      "1 Rogue One: A Star Wars Story $532,177,324\n",
      "2 Finding Dory $486,295,561\n",
      "3 Captain America: Civil War $408,084,349\n",
      "4 The Secret Life of Pets $368,384,330\n",
      "5 The Jungle Book (2016) $364,001,123\n",
      "1 Star Wars: The Force Awakens $936,662,225\n",
      "2 Jurassic World $652,270,625\n",
      "3 Avengers: Age of Ultron $459,005,868\n",
      "4 Inside Out $356,461,711\n",
      "5 Furious 7 $353,007,020\n",
      "1 American Sniper $350,126,372\n",
      "2 The Hunger Games: Mockingjay - Part 1 $337,135,885\n",
      "3 Guardians of the Galaxy $333,176,600\n",
      "4 Captain America: The Winter Soldier $259,766,572\n",
      "5 The LEGO Movie $257,760,692\n",
      "1 The Hunger Games: Catching Fire $424,668,047\n",
      "2 Iron Man 3 $409,013,994\n",
      "3 Frozen $400,738,009\n",
      "4 Despicable Me 2 $368,061,265\n",
      "5 Man of Steel $291,045,518\n",
      "1 Marvel's The Avengers $623,357,910\n",
      "2 The Dark Knight Rises $448,139,099\n",
      "3 The Hunger Games $408,010,692\n",
      "4 Skyfall $304,360,277\n",
      "5 The Hobbit: An Unexpected Journey $303,003,568\n",
      "1 Harry Potter and the Deathly Hallows Part 2 $381,011,219\n",
      "2 Transformers: Dark of the Moon $352,390,543\n",
      "3 The Twilight Saga: Breaking Dawn Part 1 $281,287,133\n",
      "4 The Hangover Part II $254,464,305\n",
      "5 Pirates of the Caribbean: On Stranger Tides $241,071,802\n",
      "1 Toy Story 3 $415,004,880\n",
      "2 Alice in Wonderland (2010) $334,191,110\n",
      "3 Iron Man 2 $312,433,331\n",
      "4 The Twilight Saga: Eclipse $300,531,751\n",
      "5 Harry Potter and the Deathly Hallows Part 1 $295,983,305\n",
      "1 Avatar $749,766,139\n",
      "2 Transformers: Revenge of the Fallen $402,111,870\n",
      "3 Harry Potter and the Half-Blood Prince $301,959,197\n",
      "4 The Twilight Saga: New Moon $296,623,634\n",
      "5 Up $293,004,164\n"
     ]
    }
   ],
   "source": [
    "# collect all necessary pieces from above to make a loop that gets top 5 movies \n",
    "# for each of the 10 years\n",
    "for year in years:\n",
    "    url = base_url + str(year)\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    tables = soup.find_all( 'table' )\n",
    "    rows = tables[6].find_all('tr')\n",
    "    for i in range(2, 7):\n",
    "        cells = rows[i].find_all('td')\n",
    "        print(cells[0].text, cells[1].text, cells[3].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293004164\n"
     ]
    }
   ],
   "source": [
    "# I realize now that each line needs to have the year also\n",
    "# and maybe I should clean the gross so it's a pure integer\n",
    "# so test that - using .strip() and .replace() chained together - \n",
    "num = '$293,004,164'\n",
    "print(num.strip('$').replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 1 Star Wars: The Last Jedi 620181382\n",
      "2017 2 Beauty and the Beast (2017) 504014165\n",
      "2017 3 Wonder Woman 412563408\n",
      "2017 4 Jumanji: Welcome to the Jungle 404515480\n",
      "2017 5 Guardians of the Galaxy Vol. 2 389813101\n",
      "2014 1 American Sniper 350126372\n",
      "2014 2 The Hunger Games: Mockingjay - Part 1 337135885\n",
      "2014 3 Guardians of the Galaxy 333176600\n",
      "2014 4 Captain America: The Winter Soldier 259766572\n",
      "2014 5 The LEGO Movie 257760692\n"
     ]
    }
   ],
   "source": [
    "miniyears = [2017, 2014]\n",
    "for year in miniyears:\n",
    "    url = base_url + str(year)\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    tables = soup.find_all( 'table' )\n",
    "    rows = tables[6].find_all('tr')\n",
    "    for i in range(2, 7):\n",
    "        cells = rows[i].find_all('td')\n",
    "        gross = cells[3].text.strip('$').replace(',', '')\n",
    "        print(year, cells[0].text, cells[1].text, gross)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'years' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\learning\\python-beginners\\web_scraping\\soup_practice.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/learning/python-beginners/web_scraping/soup_practice.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m c\u001b[39m.\u001b[39mwriterow( [\u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrank\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgross\u001b[39m\u001b[39m'\u001b[39m] )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/learning/python-beginners/web_scraping/soup_practice.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# modified code from above\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/learning/python-beginners/web_scraping/soup_practice.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m year \u001b[39min\u001b[39;00m years:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/learning/python-beginners/web_scraping/soup_practice.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     url \u001b[39m=\u001b[39m base_url \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(year)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/learning/python-beginners/web_scraping/soup_practice.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     html \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'years' is not defined"
     ]
    }
   ],
   "source": [
    "# I should really save my data into a csv\n",
    "\n",
    "import csv\n",
    "\n",
    "# open new file for writing -\n",
    "csvfile = open(\"movies.csv\", 'w', newline='', encoding='utf-8')\n",
    "\n",
    "# make a new variable, c, for Python's CSV writer object -\n",
    "c = csv.writer(csvfile)\n",
    "\n",
    "#write header row to csv\n",
    "c.writerow( ['year', 'rank', 'title', 'gross'] )\n",
    "\n",
    "# modified code from above\n",
    "for year in years:\n",
    "    url = base_url + str(year)\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    tables = soup.find_all( 'table' )\n",
    "    rows = tables[6].find_all('tr')\n",
    "    for i in range(2, 7):\n",
    "        cells = rows[i].find_all('td')\n",
    "        gross = cells[3].text.strip('$').replace(',', '')\n",
    "        # print(year, cells[0].text, cells[1].text, gross)\n",
    "        # instead of printing, I need to make a list and write that list to the CSV as one row\n",
    "        c.writerow( [year, cells[0].text, cells[1].text, gross] )\n",
    "\n",
    "# close the file\n",
    "csvfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a CSV file, named movies.csv, that has 51 rows: the header row plus 5 movies for each year from 2009 through 2018. It has four columns: year, rank, title, and gross.\n",
    "\n",
    "Note that **only the final cell above** is needed to create this CSV, by scraping 10 separate web pages. Everything *above* the final cell above is just instruction, demonstration. It is intended to show the problem-solving you need to go through to get to a desired scraping result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "937de139cb5de0efc52e063aa81b275f0e947a57fd7d3964a2c72a75200c87d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
